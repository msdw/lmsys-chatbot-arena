{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4806d5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:26:50.949932Z",
     "iopub.status.busy": "2024-07-25T14:26:50.949139Z",
     "iopub.status.idle": "2024-07-25T14:27:43.918415Z",
     "shell.execute_reply": "2024-07-25T14:27:43.917288Z"
    },
    "papermill": {
     "duration": 52.980436,
     "end_time": "2024-07-25T14:27:43.920797",
     "exception": false,
     "start_time": "2024-07-25T14:26:50.940361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/lmsyspackages1/\r\n",
      "Processing /kaggle/input/lmsyspackages1/transformers-4.44.0.dev0.zip\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.0.dev0) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.0.dev0) (0.23.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.0.dev0) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.0.dev0) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.0.dev0) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.0.dev0) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.0.dev0) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.0.dev0) (0.19.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.0.dev0) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.0.dev0) (4.66.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0.dev0) (2024.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0.dev0) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.44.0.dev0) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.44.0.dev0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.44.0.dev0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.44.0.dev0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.44.0.dev0) (2024.7.4)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.44.0.dev0-py3-none-any.whl size=9405504 sha256=2037b362ed68774c6b5282a102bf44080623f8692f1b0c4bc3b0e3db3a0ddb1b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/70/b9/f8/ca2eaba14f0638d458336da55845ab4c5db8c95d2436fdbc82\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.42.3\r\n",
      "    Uninstalling transformers-4.42.3:\r\n",
      "      Successfully uninstalled transformers-4.42.3\r\n",
      "Successfully installed transformers-4.44.0.dev0\r\n",
      "Looking in links: /kaggle/input/lmsyspackages1/\r\n",
      "Processing /kaggle/input/lmsyspackages1/bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.43.2) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.43.2) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.2) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.2) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.2) (1.13.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.2) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.2) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.2) (2024.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes==0.43.2) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes==0.43.2) (1.3.0)\r\n",
      "Installing collected packages: bitsandbytes\r\n",
      "Successfully installed bitsandbytes-0.43.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links=/kaggle/input/lmsyspackages1/ --no-build-isolation /kaggle/input/lmsyspackages1/transformers-4.44.0.dev0.zip\n",
    "!pip install --no-index --find-links=/kaggle/input/lmsyspackages1/ --no-build-isolation /kaggle/input/lmsyspackages1/bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "634cc8d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:27:43.938954Z",
     "iopub.status.busy": "2024-07-25T14:27:43.938616Z",
     "iopub.status.idle": "2024-07-25T14:27:49.697650Z",
     "shell.execute_reply": "2024-07-25T14:27:49.696852Z"
    },
    "papermill": {
     "duration": 5.770728,
     "end_time": "2024-07-25T14:27:49.700007",
     "exception": false,
     "start_time": "2024-07-25T14:27:43.929279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for loading datasets, progress tracking, and data manipulation\n",
    "from datasets import load_dataset\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Import transformers for model and tokenizer, itertools for efficient looping, and random for randomness\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import itertools\n",
    "import random\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import Template\n",
    "from pathlib import Path\n",
    "import time\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "\n",
    "# The code imports multiple modules for different functionalities:\n",
    "# - `datasets` for loading and processing datasets.\n",
    "# - `tqdm` for progress bars.\n",
    "# - `torch` for PyTorch operations.\n",
    "# - `pandas` for data manipulation.\n",
    "# - `glob` for file pattern matching.\n",
    "# - `numpy` for numerical operations.\n",
    "# - `os` for interacting with the operating system.\n",
    "# - `transformers` for model and tokenizer handling from Hugging Face.\n",
    "# - `itertools` for advanced iteration utilities.\n",
    "# - `random` for generating random numbers.\n",
    "# - `argparse` for parsing command-line arguments.\n",
    "# - `string.Template` for template string substitution.\n",
    "# - `pathlib.Path` for handling filesystem paths.\n",
    "# - `time` for time-related functions.\n",
    "# - `gc` for garbage collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f250e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:27:49.717972Z",
     "iopub.status.busy": "2024-07-25T14:27:49.717438Z",
     "iopub.status.idle": "2024-07-25T14:27:53.294502Z",
     "shell.execute_reply": "2024-07-25T14:27:53.293518Z"
    },
    "papermill": {
     "duration": 3.588547,
     "end_time": "2024-07-25T14:27:53.296780",
     "exception": false,
     "start_time": "2024-07-25T14:27:49.708233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>370945</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>[\"\\\"Bacteria is life on Mars but a heartbeat i...</td>\n",
       "      <td>[\"Dune\"]</td>\n",
       "      <td>[\"This quote seems to be referencing the debat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>738614</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>gpt4all-13b-snoozy</td>\n",
       "      <td>[\"What's the best first move in tic-tac-toe?\",...</td>\n",
       "      <td>[\"The best first move in tic-tac-toe is often ...</td>\n",
       "      <td>[\"The best first move in tic-tac-toe is to pla...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>862324</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[\"Write me a poem in urdu in the style of Iqba...</td>\n",
       "      <td>[\"Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan...</td>\n",
       "      <td>[\"In the realm of selflessness dwells the true...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1827787</td>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"Given a passage and some supplementary infor...</td>\n",
       "      <td>[\"Refined passage: \\nThe person in the photo i...</td>\n",
       "      <td>[\"Refined passage: \\nThe person in the photo i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                model_a             model_b  \\\n",
       "0     30192     gpt-4-1106-preview          gpt-4-0613   \n",
       "7    370945             gemini-pro          claude-2.0   \n",
       "13   738614           mpt-30b-chat  gpt4all-13b-snoozy   \n",
       "14   862324             vicuna-13b           koala-13b   \n",
       "29  1827787  deepseek-llm-67b-chat  gpt-4-1106-preview   \n",
       "\n",
       "                                               prompt  \\\n",
       "0   [\"Is it morally right to try to have a certain...   \n",
       "7   [\"\\\"Bacteria is life on Mars but a heartbeat i...   \n",
       "13  [\"What's the best first move in tic-tac-toe?\",...   \n",
       "14  [\"Write me a poem in urdu in the style of Iqba...   \n",
       "29  [\"Given a passage and some supplementary infor...   \n",
       "\n",
       "                                           response_a  \\\n",
       "0   [\"The question of whether it is morally right ...   \n",
       "7                                            [\"Dune\"]   \n",
       "13  [\"The best first move in tic-tac-toe is often ...   \n",
       "14  [\"Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan...   \n",
       "29  [\"Refined passage: \\nThe person in the photo i...   \n",
       "\n",
       "                                           response_b  winner_model_a  \\\n",
       "0   [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "7   [\"This quote seems to be referencing the debat...               0   \n",
       "13  [\"The best first move in tic-tac-toe is to pla...               1   \n",
       "14  [\"In the realm of selflessness dwells the true...               0   \n",
       "29  [\"Refined passage: \\nThe person in the photo i...               0   \n",
       "\n",
       "    winner_model_b  winner_tie  fold  \n",
       "0                0           0     0  \n",
       "7                1           0     0  \n",
       "13               0           0     0  \n",
       "14               0           1     0  \n",
       "29               0           1     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from pathlib import Path  # For handling file paths\n",
    "import os  # For accessing environment variables\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "\n",
    "# Define the path to the data directory\n",
    "data_path = Path('/kaggle/input/lmsys-chatbot-arena')\n",
    "\n",
    "# Check if the environment variable 'KAGGLE_IS_COMPETITION_RERUN' is set\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # If the code is running in a competition rerun, load the test data\n",
    "    test = pd.read_csv(data_path / 'test.csv')\n",
    "else:\n",
    "    # If the code is not running in a competition rerun, load the folds data\n",
    "    folds = pd.read_csv(\"/kaggle/input/lmsysfolds/folds.csv\")\n",
    "    # Load the training data\n",
    "    test = pd.read_csv(data_path / 'train.csv')\n",
    "    # Merge the training data with the folds data on the 'id' column\n",
    "    test = test.merge(folds, on=\"id\")\n",
    "    # Filter the data to only include rows where the fold is 0\n",
    "    test = test.loc[test[\"fold\"] == 0]\n",
    "    # Select the first 100 rows of the filtered data\n",
    "    test = test.head(100)\n",
    "\n",
    "# Replace any missing values with empty strings\n",
    "test = test.fillna(\"\")\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab420eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:27:53.315986Z",
     "iopub.status.busy": "2024-07-25T14:27:53.315654Z",
     "iopub.status.idle": "2024-07-25T14:27:53.325269Z",
     "shell.execute_reply": "2024-07-25T14:27:53.324331Z"
    },
    "papermill": {
     "duration": 0.021363,
     "end_time": "2024-07-25T14:27:53.327316",
     "exception": false,
     "start_time": "2024-07-25T14:27:53.305953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "test[\"prompt\"] = test[\"prompt\"].apply(lambda x: json.loads(x))\n",
    "test[\"response_a\"] = test[\"response_a\"].apply(lambda x: json.loads(x))\n",
    "test[\"response_b\"] = test[\"response_b\"].apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a71b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:27:53.346432Z",
     "iopub.status.busy": "2024-07-25T14:27:53.346105Z",
     "iopub.status.idle": "2024-07-25T14:27:53.425705Z",
     "shell.execute_reply": "2024-07-25T14:27:53.424929Z"
    },
    "papermill": {
     "duration": 0.091684,
     "end_time": "2024-07-25T14:27:53.427772",
     "exception": false,
     "start_time": "2024-07-25T14:27:53.336088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the full prompts\n",
    "full_prompts = []\n",
    "\n",
    "# Iterate over each row in the test DataFrame\n",
    "for idx, row in test.iterrows():\n",
    "    # Initialize an empty string to build the full prompt for each row\n",
    "    full_prompt = \"\"\n",
    "\n",
    "    # Iterate over each prompt in the row\n",
    "    for i in range(len(row[\"prompt\"])):\n",
    "        # Add turn information to the prompt\n",
    "        full_prompt += f\"## Turn {i + 1}\\n\\n\"\n",
    "        \n",
    "        # Get response A, handling None values\n",
    "        if row[\"response_a\"][i] is None:\n",
    "            res_a = \"None\"\n",
    "        else:\n",
    "            res_a = row[\"response_a\"][i]\n",
    "        \n",
    "        # Get response B, handling None values\n",
    "        if row[\"response_b\"][i] is None:\n",
    "            res_b = \"None\"\n",
    "        else:\n",
    "            res_b = row[\"response_b\"][i]\n",
    "        \n",
    "        # Construct the prompt with responses A and B\n",
    "        full_prompt += \"### Prompt\\n\" + row[\"prompt\"][i] + \"\\n\\n### Response A\\n\" + res_a + \"\\n\\n### Response B\\n\" + res_b + \"\\n\\n\"\n",
    "    \n",
    "    # Add the final question to the prompt\n",
    "    full_prompt += \"## Which response is better?\"\n",
    "    \n",
    "    # Append the constructed prompt to the list\n",
    "    full_prompts.append(full_prompt)\n",
    "\n",
    "# Initialize another list to store the full prompts for test-time augmentation (TTA)\n",
    "full_prompts_tta = []\n",
    "\n",
    "# Iterate over each row in the test DataFrame again for TTA\n",
    "for idx, row in test.iterrows():\n",
    "    # Initialize an empty string to build the full prompt for each row\n",
    "    full_prompt = \"\"\n",
    "\n",
    "    # Iterate over each prompt in the row\n",
    "    for i in range(len(row[\"prompt\"])):\n",
    "        # Add turn information to the prompt\n",
    "        full_prompt += f\"## Turn {i + 1}\\n\\n\"\n",
    "        \n",
    "        # Get response A, handling None values, but switch response A and B compared to the previous iteration\n",
    "        if row[\"response_a\"][i] is None:\n",
    "            res_a = \"None\"\n",
    "        else:\n",
    "            res_a = row[\"response_a\"][i]\n",
    "        \n",
    "        # Get response B, handling None values\n",
    "        if row[\"response_b\"][i] is None:\n",
    "            res_b = \"None\"\n",
    "        else:\n",
    "            res_b = row[\"response_b\"][i]\n",
    "        \n",
    "        # Construct the prompt with responses A and B switched\n",
    "        full_prompt += \"### Prompt\\n\" + row[\"prompt\"][i] + \"\\n\\n### Response A\\n\" + res_b + \"\\n\\n### Response B\\n\" + res_a + \"\\n\\n\"\n",
    "    \n",
    "    # Add the final question to the prompt\n",
    "    full_prompt += \"## Which response is better?\"\n",
    "    \n",
    "    # Append the constructed prompt to the TTA list\n",
    "    full_prompts_tta.append(full_prompt)\n",
    "\n",
    "# Assign the full prompts to a new column in the test DataFrame\n",
    "test[\"full_prompt\"] = full_prompts\n",
    "\n",
    "# Save the modified DataFrame to a parquet file\n",
    "test.to_parquet(\"test.pq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc6d515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:27:53.446159Z",
     "iopub.status.busy": "2024-07-25T14:27:53.445865Z",
     "iopub.status.idle": "2024-07-25T14:27:53.456622Z",
     "shell.execute_reply": "2024-07-25T14:27:53.455715Z"
    },
    "papermill": {
     "duration": 0.022659,
     "end_time": "2024-07-25T14:27:53.458885",
     "exception": false,
     "start_time": "2024-07-25T14:27:53.436226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing process.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile process.py\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, Gemma2Model\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# Setting environment variables for transformers and PyTorch\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "def sort_and_batch_samples(data, tokenizer, max_length):\n",
    "    # Tokenizing the data without adding special tokens and with truncation\n",
    "    encoded = tokenizer(data['full_prompt'].tolist(), add_special_tokens=False, truncation=True, max_length=max_length, padding=False, return_tensors=None)\n",
    "    \n",
    "    # Calculate lengths of tokenized inputs\n",
    "    lengths = [len(ids) for ids in encoded['input_ids']]\n",
    "    \n",
    "    # Sort indices by length in descending order\n",
    "    sorted_indices = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True)\n",
    "    sorted_data = data.iloc[sorted_indices].reset_index(drop=True)\n",
    "    sorted_encoded = {k: [v[i] for i in sorted_indices] for k, v in encoded.items()}\n",
    "    sorted_lengths = [lengths[i] for i in sorted_indices]\n",
    "    \n",
    "    # Map original indices to sorted indices\n",
    "    position_map = {i: idx for idx, i in enumerate(sorted_indices)}\n",
    "    \n",
    "    return sorted_data, sorted_encoded, sorted_lengths, position_map\n",
    "\n",
    "def dynamic_batch(sorted_data, sorted_lengths, max_tokens, tokenizer, device):\n",
    "    # Function to dynamically batch the data based on token lengths and max tokens per batch\n",
    "    batches = []\n",
    "    current_batch = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for i, length in enumerate(sorted_lengths):\n",
    "        if current_length + length > max_tokens and current_batch:\n",
    "            # If current batch exceeds max_tokens, yield the batch\n",
    "            yield tokenizer(sorted_data.loc[current_batch, 'full_prompt'].tolist(), \n",
    "                            return_tensors=\"pt\", \n",
    "                            padding=True, \n",
    "                            truncation=True, \n",
    "                            max_length=max(sorted_lengths[j] for j in current_batch)\n",
    "                           ).to(device), current_batch\n",
    "            current_batch = []\n",
    "            current_length = 0\n",
    "        \n",
    "        current_batch.append(i)\n",
    "        current_length += length\n",
    "    \n",
    "    if current_batch:\n",
    "        # Yield the last batch if there are remaining items\n",
    "        yield tokenizer(sorted_data.loc[current_batch, 'full_prompt'].tolist(), \n",
    "                        return_tensors=\"pt\", \n",
    "                        padding=True, \n",
    "                        truncation=True, \n",
    "                        max_length=max(sorted_lengths[j] for j in current_batch)\n",
    "                       ).to(device), current_batch\n",
    "\n",
    "@torch.no_grad()\n",
    "def process_batches(model, head, batches, position_map, device):\n",
    "    # Process each batch to get logits\n",
    "    all_logits = []\n",
    "    all_indices = []\n",
    "    for batch, indices in tqdm(batches, desc=\"Processing batches\"):\n",
    "        with autocast():\n",
    "            out = model(**batch)\n",
    "            pooled = out[0][:, -1].to(device)  # Get the last hidden state\n",
    "            logits = F.softmax(head(pooled.float()), dim=1).cpu()  # Apply the head and softmax\n",
    "        all_logits.append(logits)\n",
    "        all_indices.extend(indices)\n",
    "    \n",
    "    # Combine logits and reorder them to match the original order\n",
    "    combined_logits = torch.cat(all_logits).numpy()\n",
    "    reordered_logits = np.zeros_like(combined_logits)\n",
    "    for i, idx in enumerate(all_indices):\n",
    "        reordered_logits[position_map[idx]] = combined_logits[i]\n",
    "    \n",
    "    return reordered_logits\n",
    "\n",
    "def split_data_by_length(data, tokenizer, max_length, num_gpus):\n",
    "    # Tokenize and calculate lengths of the inputs\n",
    "    encoded = tokenizer(data['full_prompt'].tolist(), add_special_tokens=False, truncation=True, max_length=max_length, padding=False, return_tensors=None)\n",
    "    lengths = [len(ids) for ids in encoded['input_ids']]\n",
    "    \n",
    "    # Sort indices by length in descending order\n",
    "    sorted_indices = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True)\n",
    "    total_length = sum(lengths)\n",
    "    target_length_per_gpu = total_length // num_gpus\n",
    "    \n",
    "    # Split the data across GPUs\n",
    "    gpu_splits = [[] for _ in range(num_gpus)]\n",
    "    current_lengths = [0] * num_gpus\n",
    "    \n",
    "    for idx in sorted_indices:\n",
    "        target_gpu = min(range(num_gpus), key=lambda i: current_lengths[i])\n",
    "        gpu_splits[target_gpu].append(idx)\n",
    "        current_lengths[target_gpu] += lengths[idx]\n",
    "    \n",
    "    return gpu_splits\n",
    "\n",
    "def main(args):\n",
    "    # Load the test data\n",
    "    test = pd.read_parquet(\"test.pq\")\n",
    "    \n",
    "    model_name = f\"/kaggle/input/{args.model}\"\n",
    "    device_map = {\"\": args.device} if args.device != \"cuda\" else \"auto\"\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "        bnb_8bit_compute_dtype=torch.float16,\n",
    "        bnb_8bit_use_double_quant=False,\n",
    "    )\n",
    "    \n",
    "    # Load the model with the specified configuration\n",
    "    model = Gemma2Model.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=device_map,\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=bnb_config\n",
    "    )\n",
    "    \n",
    "    # Load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        use_fast=True,\n",
    "        trust_remote_code=True,\n",
    "        from_slow=True,\n",
    "        add_prefix_space=False,\n",
    "        padding_side=\"left\",\n",
    "        truncation_side=\"left\"\n",
    "    )\n",
    "    \n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.config.attn_logit_softcapping = None\n",
    "    \n",
    "    model_device = args.device\n",
    "    if args.device == \"cuda\":\n",
    "        model_device = \"cuda:0\"\n",
    "    \n",
    "    # Load the classification head weights\n",
    "    head_weights = torch.load(f\"/kaggle/input/{args.model}/classification_head.pth\", map_location=model_device)\n",
    "    head = torch.nn.Linear(model.config.hidden_size, 1, bias=False).to(model_device)\n",
    "    head.weight.data = head_weights\n",
    "    \n",
    "    max_length = 2048  # Adjust as needed\n",
    "    \n",
    "    # Split the data across GPUs\n",
    "    num_gpus = 1 if args.device == \"cuda\" else 2\n",
    "    gpu_splits = split_data_by_length(test, tokenizer, max_length, num_gpus)\n",
    "    \n",
    "    orig_len = len(test)\n",
    "    \n",
    "    if args.device.startswith(\"cuda:\"):\n",
    "        device_id = int(args.device.split(':')[1])\n",
    "        current_indices = gpu_splits[device_id]\n",
    "        test = test.iloc[current_indices].copy()\n",
    "    elif args.device == \"cuda\":\n",
    "        # If using all GPUs, process the entire dataset\n",
    "        current_indices = gpu_splits[0]\n",
    "        test = test.iloc[current_indices].copy()\n",
    "\n",
    "    # Sort and batch the samples\n",
    "    sorted_data, sorted_encoded, sorted_lengths, position_map = sort_and_batch_samples(test, tokenizer, max_length)\n",
    "    \n",
    "    max_tokens = 2048 * 2\n",
    "    \n",
    "    # Create dynamic batches\n",
    "    batches = dynamic_batch(sorted_data, sorted_lengths, max_tokens, tokenizer, args.device)\n",
    "    \n",
    "    # Process the batches to get logits\n",
    "    all_logits = process_batches(model, head, batches, position_map, model_device)\n",
    "    \n",
    "    # Reorder logits to match the original data order\n",
    "    final_logits = np.zeros((orig_len, all_logits.shape[1]))\n",
    "    for i, orig_idx in enumerate(current_indices):\n",
    "        final_logits[orig_idx] = all_logits[i]\n",
    "    \n",
    "    # Save the logits to file\n",
    "    if args.device == \"cuda\":\n",
    "        np.save(\"probs\", final_logits)\n",
    "    elif args.device.startswith(\"cuda:\"):\n",
    "        np.save(f\"probs_v{args.device.split(':')[1]}\", final_logits)\n",
    "    else:\n",
    "        np.save(\"probs_cpu\", final_logits)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set up argument parser and execute main function\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model\", type=str, required=True)\n",
    "    parser.add_argument(\"--device\", type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6abf11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:27:53.477139Z",
     "iopub.status.busy": "2024-07-25T14:27:53.476836Z",
     "iopub.status.idle": "2024-07-25T14:27:53.482994Z",
     "shell.execute_reply": "2024-07-25T14:27:53.481920Z"
    },
    "papermill": {
     "duration": 0.017445,
     "end_time": "2024-07-25T14:27:53.484984",
     "exception": false,
     "start_time": "2024-07-25T14:27:53.467539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing process.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile process.sh\n",
    "python process.py --model \"lmsysmodel0\" --device \"cuda:0\" &\n",
    "python process.py --model \"lmsysmodel0\" --device \"cuda:1\" &\n",
    "wait \n",
    "echo \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186120f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:27:53.503232Z",
     "iopub.status.busy": "2024-07-25T14:27:53.502917Z",
     "iopub.status.idle": "2024-07-25T14:31:12.378359Z",
     "shell.execute_reply": "2024-07-25T14:31:12.377098Z"
    },
    "papermill": {
     "duration": 198.887769,
     "end_time": "2024-07-25T14:31:12.381418",
     "exception": false,
     "start_time": "2024-07-25T14:27:53.493649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\r\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\r\n",
      "Unused kwargs: ['bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\r\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [02:12<00:00, 33.13s/it]\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [02:12<00:00, 33.18s/it]\r\n",
      "Processing batches: 0it [00:00, ?it/s]2024-07-25 14:30:24.689714: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-07-25 14:30:24.689721: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-07-25 14:30:24.689813: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-07-25 14:30:24.689847: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-07-25 14:30:24.817794: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "2024-07-25 14:30:24.817808: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Processing batches: 10it [00:51,  5.19s/it]\r\n",
      "Processing batches: 10it [00:52,  5.28s/it]\r\n",
      "Done\r\n"
     ]
    }
   ],
   "source": [
    "!sh process.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d037eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:31:12.410579Z",
     "iopub.status.busy": "2024-07-25T14:31:12.410186Z",
     "iopub.status.idle": "2024-07-25T14:31:12.416361Z",
     "shell.execute_reply": "2024-07-25T14:31:12.415578Z"
    },
    "papermill": {
     "duration": 0.022777,
     "end_time": "2024-07-25T14:31:12.418421",
     "exception": false,
     "start_time": "2024-07-25T14:31:12.395644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits = np.load(\"probs_v0.npy\") + np.load(\"probs_v1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a40c946b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:31:12.442614Z",
     "iopub.status.busy": "2024-07-25T14:31:12.442260Z",
     "iopub.status.idle": "2024-07-25T14:31:12.458913Z",
     "shell.execute_reply": "2024-07-25T14:31:12.458147Z"
    },
    "papermill": {
     "duration": 0.031075,
     "end_time": "2024-07-25T14:31:12.461037",
     "exception": false,
     "start_time": "2024-07-25T14:31:12.429962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[\"full_prompt\"] = full_prompts_tta\n",
    "test.to_parquet(\"test.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9afa31c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:31:12.484952Z",
     "iopub.status.busy": "2024-07-25T14:31:12.484669Z",
     "iopub.status.idle": "2024-07-25T14:32:31.313141Z",
     "shell.execute_reply": "2024-07-25T14:32:31.312054Z"
    },
    "papermill": {
     "duration": 78.843289,
     "end_time": "2024-07-25T14:32:31.315712",
     "exception": false,
     "start_time": "2024-07-25T14:31:12.472423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\r\n",
      "Unused kwargs: ['bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\r\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\r\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:20<00:00,  5.00s/it]\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:19<00:00,  4.98s/it]\r\n",
      "Processing batches: 0it [00:00, ?it/s]2024-07-25 14:31:48.888832: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-07-25 14:31:48.888898: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-07-25 14:31:48.890930: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "2024-07-25 14:31:49.100452: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-07-25 14:31:49.100536: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-07-25 14:31:49.102332: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Processing batches: 10it [00:44,  4.48s/it]\r\n",
      "Processing batches: 10it [00:45,  4.59s/it]\r\n",
      "Done\r\n"
     ]
    }
   ],
   "source": [
    "!sh process.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f6ceaf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:32:31.349482Z",
     "iopub.status.busy": "2024-07-25T14:32:31.348703Z",
     "iopub.status.idle": "2024-07-25T14:32:31.363452Z",
     "shell.execute_reply": "2024-07-25T14:32:31.362561Z"
    },
    "papermill": {
     "duration": 0.034639,
     "end_time": "2024-07-25T14:32:31.365970",
     "exception": false,
     "start_time": "2024-07-25T14:32:31.331331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08838718, 0.80410892, 0.10750396],\n",
       "       [0.79719859, 0.07054841, 0.13225305],\n",
       "       [0.10234115, 0.70382839, 0.19383045],\n",
       "       [0.17838791, 0.2710644 , 0.55054766],\n",
       "       [0.06668481, 0.06853338, 0.8647818 ],\n",
       "       [0.29336137, 0.41247043, 0.2941682 ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.25617051, 0.38137859, 0.36245096],\n",
       "       [0.26612595, 0.31987479, 0.41399926],\n",
       "       [0.27281049, 0.16268398, 0.56450552],\n",
       "       [0.15120441, 0.63815039, 0.21064526],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.83956522, 0.03884743, 0.12158739],\n",
       "       [0.40776941, 0.2163005 , 0.37593004],\n",
       "       [0.51514214, 0.10677379, 0.37808412],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.28831202, 0.1377859 , 0.57390207],\n",
       "       [0.19321972, 0.06413557, 0.74264473],\n",
       "       [0.5640229 , 0.17412996, 0.26184714],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.68495983, 0.10200923, 0.21303089],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.03593907, 0.60845715, 0.35560381],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.43756598, 0.20608689, 0.35634708],\n",
       "       [0.00217495, 0.94319206, 0.05463295],\n",
       "       [0.24966989, 0.43594351, 0.31438667],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.25468314, 0.42537013, 0.31994668],\n",
       "       [0.17940594, 0.2186887 , 0.60190547],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.46360683, 0.139268  , 0.39712524],\n",
       "       [0.28910032, 0.33837113, 0.37252858],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.06386214, 0.07707007, 0.8590678 ],\n",
       "       [0.04832653, 0.70325196, 0.24842149],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.85917664, 0.040145  , 0.10067843],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.28945681, 0.50418222, 0.20636103],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.51390004, 0.26652646, 0.2195735 ],\n",
       "       [0.69668549, 0.09837773, 0.20493674],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.54187924, 0.18708567, 0.27103513],\n",
       "       [0.92244291, 0.01470744, 0.0628497 ],\n",
       "       [0.5149703 , 0.10036919, 0.38466051],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.46163663, 0.20420089, 0.3341625 ],\n",
       "       [0.63634431, 0.1039311 , 0.25972456],\n",
       "       [0.41074267, 0.29078057, 0.29847673],\n",
       "       [0.27055117, 0.47919929, 0.25024951],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.37031278, 0.31586692, 0.31382033],\n",
       "       [0.18129204, 0.57361859, 0.24508938],\n",
       "       [0.156608  , 0.54475045, 0.29864156],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.30731165, 0.25785214, 0.43483618],\n",
       "       [0.31055456, 0.45624667, 0.23319875],\n",
       "       [0.26929656, 0.4623585 , 0.26834494],\n",
       "       [0.04562391, 0.6776793 , 0.27669677],\n",
       "       [0.1516853 , 0.58346009, 0.26485464],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.19630344, 0.49218327, 0.31151336],\n",
       "       [0.23236685, 0.40336064, 0.36427253],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.18581772, 0.46828753, 0.34589475],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.29620257, 0.34240767, 0.36138979]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.load(\"probs_v0.npy\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f714b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:32:31.399937Z",
     "iopub.status.busy": "2024-07-25T14:32:31.399585Z",
     "iopub.status.idle": "2024-07-25T14:32:31.404773Z",
     "shell.execute_reply": "2024-07-25T14:32:31.403952Z"
    },
    "papermill": {
     "duration": 0.02476,
     "end_time": "2024-07-25T14:32:31.406931",
     "exception": false,
     "start_time": "2024-07-25T14:32:31.382171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits_tta = np.load(\"probs_v0.npy\") + np.load(\"probs_v1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5f96332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:32:31.439231Z",
     "iopub.status.busy": "2024-07-25T14:32:31.438886Z",
     "iopub.status.idle": "2024-07-25T14:32:31.444032Z",
     "shell.execute_reply": "2024-07-25T14:32:31.443192Z"
    },
    "papermill": {
     "duration": 0.023714,
     "end_time": "2024-07-25T14:32:31.446198",
     "exception": false,
     "start_time": "2024-07-25T14:32:31.422484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits_combined = logits / 2\n",
    "logits_combined[:,0] += logits_tta[:,1] / 2\n",
    "logits_combined[:,1] += logits_tta[:,0] / 2\n",
    "logits_combined[:,2] += logits_tta[:,2] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ad546f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:32:31.478109Z",
     "iopub.status.busy": "2024-07-25T14:32:31.477804Z",
     "iopub.status.idle": "2024-07-25T14:32:31.483937Z",
     "shell.execute_reply": "2024-07-25T14:32:31.482943Z"
    },
    "papermill": {
     "duration": 0.024691,
     "end_time": "2024-07-25T14:32:31.486321",
     "exception": false,
     "start_time": "2024-07-25T14:32:31.461630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = test.fillna(1/3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99c60e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:32:31.518402Z",
     "iopub.status.busy": "2024-07-25T14:32:31.518098Z",
     "iopub.status.idle": "2024-07-25T14:32:31.553040Z",
     "shell.execute_reply": "2024-07-25T14:32:31.552028Z"
    },
    "papermill": {
     "duration": 0.05304,
     "end_time": "2024-07-25T14:32:31.555472",
     "exception": false,
     "start_time": "2024-07-25T14:32:31.502432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>fold</th>\n",
       "      <th>full_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[Is it morally right to try to have a certain ...</td>\n",
       "      <td>[The question of whether it is morally right t...</td>\n",
       "      <td>[As an AI, I don't have personal beliefs or op...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nIs it morally right t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>370945</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>[\"Bacteria is life on Mars but a heartbeat isn...</td>\n",
       "      <td>[Dune]</td>\n",
       "      <td>[This quote seems to be referencing the debate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\n\"Bacteria is life on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>738614</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>gpt4all-13b-snoozy</td>\n",
       "      <td>[What's the best first move in tic-tac-toe?, T...</td>\n",
       "      <td>[The best first move in tic-tac-toe is often c...</td>\n",
       "      <td>[The best first move in tic-tac-toe is to plac...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nWhat's the best first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>862324</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[Write me a poem in urdu in the style of Iqbal...</td>\n",
       "      <td>[Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan ...</td>\n",
       "      <td>[In the realm of selflessness dwells the true ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nWrite me a poem in ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1827787</td>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[Given a passage and some supplementary inform...</td>\n",
       "      <td>[Refined passage: \\nThe person in the photo is...</td>\n",
       "      <td>[Refined passage: \\nThe person in the photo is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nGiven a passage and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>37132737</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>pplx-70b-online</td>\n",
       "      <td>[What is the basque country?]</td>\n",
       "      <td>[The Basque Country is a region located in the...</td>\n",
       "      <td>[The Basque Country is a region located in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nWhat is the basque co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>37206390</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>[what is the song in the movie snatch that pla...</td>\n",
       "      <td>[The song that plays during the hare and dog s...</td>\n",
       "      <td>[The song that plays during the hare coursing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nwhat is the song in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>37951752</td>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>[Would you like to play my DnD game?, Ok, make...</td>\n",
       "      <td>[As an AI language model, I'm not capable of p...</td>\n",
       "      <td>[Thank you for the invitation! I'd be happy to...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nWould you like to pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>38558732</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[Could you please explain what does it mean fo...</td>\n",
       "      <td>[In physics, the concept of time being fundame...</td>\n",
       "      <td>[When time is considered fundamental, it means...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nCould you please expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>38760658</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[Write an interesting short sci Fi story]</td>\n",
       "      <td>[In the year 2075, humanity made a groundbreak...</td>\n",
       "      <td>[In the year 2150, the world was on the brink ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nWrite an interesting ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                model_a                     model_b  \\\n",
       "0       30192     gpt-4-1106-preview                  gpt-4-0613   \n",
       "7      370945             gemini-pro                  claude-2.0   \n",
       "13     738614           mpt-30b-chat          gpt4all-13b-snoozy   \n",
       "14     862324             vicuna-13b                   koala-13b   \n",
       "29    1827787  deepseek-llm-67b-chat          gpt-4-1106-preview   \n",
       "..        ...                    ...                         ...   \n",
       "502  37132737     gpt-3.5-turbo-0613             pplx-70b-online   \n",
       "504  37206390             gpt-4-0613          gpt-4-0125-preview   \n",
       "516  37951752  deepseek-llm-67b-chat  mixtral-8x7b-instruct-v0.1   \n",
       "519  38558732       llama-2-13b-chat         mistral-7b-instruct   \n",
       "520  38760658         mistral-medium          gpt-3.5-turbo-1106   \n",
       "\n",
       "                                                prompt  \\\n",
       "0    [Is it morally right to try to have a certain ...   \n",
       "7    [\"Bacteria is life on Mars but a heartbeat isn...   \n",
       "13   [What's the best first move in tic-tac-toe?, T...   \n",
       "14   [Write me a poem in urdu in the style of Iqbal...   \n",
       "29   [Given a passage and some supplementary inform...   \n",
       "..                                                 ...   \n",
       "502                      [What is the basque country?]   \n",
       "504  [what is the song in the movie snatch that pla...   \n",
       "516  [Would you like to play my DnD game?, Ok, make...   \n",
       "519  [Could you please explain what does it mean fo...   \n",
       "520          [Write an interesting short sci Fi story]   \n",
       "\n",
       "                                            response_a  \\\n",
       "0    [The question of whether it is morally right t...   \n",
       "7                                               [Dune]   \n",
       "13   [The best first move in tic-tac-toe is often c...   \n",
       "14   [Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan ...   \n",
       "29   [Refined passage: \\nThe person in the photo is...   \n",
       "..                                                 ...   \n",
       "502  [The Basque Country is a region located in the...   \n",
       "504  [The song that plays during the hare and dog s...   \n",
       "516  [As an AI language model, I'm not capable of p...   \n",
       "519  [In physics, the concept of time being fundame...   \n",
       "520  [In the year 2075, humanity made a groundbreak...   \n",
       "\n",
       "                                            response_b  winner_model_a  \\\n",
       "0    [As an AI, I don't have personal beliefs or op...               1   \n",
       "7    [This quote seems to be referencing the debate...               0   \n",
       "13   [The best first move in tic-tac-toe is to plac...               1   \n",
       "14   [In the realm of selflessness dwells the true ...               0   \n",
       "29   [Refined passage: \\nThe person in the photo is...               0   \n",
       "..                                                 ...             ...   \n",
       "502  [The Basque Country is a region located in the...               0   \n",
       "504  [The song that plays during the hare coursing ...               1   \n",
       "516  [Thank you for the invitation! I'd be happy to...               0   \n",
       "519  [When time is considered fundamental, it means...               1   \n",
       "520  [In the year 2150, the world was on the brink ...               1   \n",
       "\n",
       "     winner_model_b  winner_tie  fold  \\\n",
       "0                 0           0     0   \n",
       "7                 1           0     0   \n",
       "13                0           0     0   \n",
       "14                0           1     0   \n",
       "29                0           1     0   \n",
       "..              ...         ...   ...   \n",
       "502               1           0     0   \n",
       "504               0           0     0   \n",
       "516               1           0     0   \n",
       "519               0           0     0   \n",
       "520               0           0     0   \n",
       "\n",
       "                                           full_prompt  \n",
       "0    ## Turn 1\\n\\n### Prompt\\nIs it morally right t...  \n",
       "7    ## Turn 1\\n\\n### Prompt\\n\"Bacteria is life on ...  \n",
       "13   ## Turn 1\\n\\n### Prompt\\nWhat's the best first...  \n",
       "14   ## Turn 1\\n\\n### Prompt\\nWrite me a poem in ur...  \n",
       "29   ## Turn 1\\n\\n### Prompt\\nGiven a passage and s...  \n",
       "..                                                 ...  \n",
       "502  ## Turn 1\\n\\n### Prompt\\nWhat is the basque co...  \n",
       "504  ## Turn 1\\n\\n### Prompt\\nwhat is the song in t...  \n",
       "516  ## Turn 1\\n\\n### Prompt\\nWould you like to pla...  \n",
       "519  ## Turn 1\\n\\n### Prompt\\nCould you please expl...  \n",
       "520  ## Turn 1\\n\\n### Prompt\\nWrite an interesting ...  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a336eeba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:32:31.590251Z",
     "iopub.status.busy": "2024-07-25T14:32:31.589437Z",
     "iopub.status.idle": "2024-07-25T14:32:31.600178Z",
     "shell.execute_reply": "2024-07-25T14:32:31.599298Z"
    },
    "papermill": {
     "duration": 0.029782,
     "end_time": "2024-07-25T14:32:31.602388",
     "exception": false,
     "start_time": "2024-07-25T14:32:31.572606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82643268, 0.07703017, 0.09653715],\n",
       "       [0.08829809, 0.74066409, 0.17103785],\n",
       "       [0.73456872, 0.09576989, 0.16966139],\n",
       "       [0.27896465, 0.17629373, 0.54474163],\n",
       "       [0.06694654, 0.06660179, 0.86645165],\n",
       "       [0.43727775, 0.28652456, 0.27619769],\n",
       "       [0.52738227, 0.27267491, 0.1999428 ],\n",
       "       [0.37115289, 0.34354806, 0.28529906],\n",
       "       [0.33474277, 0.30421737, 0.36103988],\n",
       "       [0.29249652, 0.28690934, 0.42059416],\n",
       "       [0.16808184, 0.23067547, 0.60124266],\n",
       "       [0.63099402, 0.1503617 , 0.21864434],\n",
       "       [0.32603386, 0.27336882, 0.40059733],\n",
       "       [0.18497277, 0.2375885 , 0.57743871],\n",
       "       [0.4029188 , 0.27784361, 0.31923756],\n",
       "       [0.39152078, 0.20563479, 0.4028444 ],\n",
       "       [0.03411086, 0.83783454, 0.1280546 ],\n",
       "       [0.29886857, 0.35408919, 0.34704222],\n",
       "       [0.12419415, 0.44966961, 0.42613629],\n",
       "       [0.26620451, 0.33619013, 0.39760533],\n",
       "       [0.25242854, 0.16163663, 0.58593488],\n",
       "       [0.54435205, 0.15620757, 0.29944037],\n",
       "       [0.16202556, 0.27709089, 0.56088358],\n",
       "       [0.0866202 , 0.14599022, 0.7673896 ],\n",
       "       [0.21503328, 0.51743862, 0.2675281 ],\n",
       "       [0.27550037, 0.1644749 , 0.56002471],\n",
       "       [0.19702838, 0.38103792, 0.42193373],\n",
       "       [0.07723511, 0.71900523, 0.20375966],\n",
       "       [0.02435942, 0.87425083, 0.10138974],\n",
       "       [0.48375143, 0.07952816, 0.43672043],\n",
       "       [0.22177498, 0.40756169, 0.37066334],\n",
       "       [0.54255091, 0.20273349, 0.25471555],\n",
       "       [0.13334972, 0.25903533, 0.60761496],\n",
       "       [0.23579404, 0.34626628, 0.41793966],\n",
       "       [0.18225309, 0.47560096, 0.34214595],\n",
       "       [0.93135196, 0.00726628, 0.06138176],\n",
       "       [0.48630197, 0.22593839, 0.28775968],\n",
       "       [0.27999283, 0.40013292, 0.31987424],\n",
       "       [0.4895265 , 0.20284125, 0.30763222],\n",
       "       [0.25505081, 0.18339708, 0.56155217],\n",
       "       [0.33240701, 0.29339643, 0.37419653],\n",
       "       [0.51608133, 0.21621034, 0.26770835],\n",
       "       [0.10402347, 0.57174239, 0.32423419],\n",
       "       [0.41642942, 0.24066569, 0.34290493],\n",
       "       [0.11921092, 0.36560611, 0.51518297],\n",
       "       [0.43230979, 0.23613991, 0.33155027],\n",
       "       [0.2378523 , 0.58419067, 0.17795701],\n",
       "       [0.74193138, 0.04984672, 0.2082219 ],\n",
       "       [0.03122344, 0.88150078, 0.08727581],\n",
       "       [0.07050235, 0.05715764, 0.87234002],\n",
       "       [0.72277525, 0.05264382, 0.22458091],\n",
       "       [0.37323363, 0.26590036, 0.36086597],\n",
       "       [0.13780682, 0.64173245, 0.22046079],\n",
       "       [0.03408577, 0.86980644, 0.09610782],\n",
       "       [0.23244448, 0.4351874 , 0.33236812],\n",
       "       [0.20505429, 0.15182116, 0.64312452],\n",
       "       [0.41062944, 0.37225592, 0.21711467],\n",
       "       [0.00589655, 0.93599114, 0.05811232],\n",
       "       [0.81019977, 0.04939874, 0.14040148],\n",
       "       [0.43811657, 0.12480278, 0.43708073],\n",
       "       [0.26074609, 0.50912189, 0.23013201],\n",
       "       [0.14233693, 0.62820232, 0.22946073],\n",
       "       [0.27974087, 0.35823192, 0.36202723],\n",
       "       [0.22065396, 0.4807664 , 0.29857963],\n",
       "       [0.00999976, 0.93123093, 0.05876933],\n",
       "       [0.14874354, 0.45934501, 0.39191146],\n",
       "       [0.34045196, 0.33008485, 0.32946321],\n",
       "       [0.17054778, 0.46107782, 0.36837441],\n",
       "       [0.45875186, 0.2689008 , 0.27234733],\n",
       "       [0.25601406, 0.39119563, 0.35279034],\n",
       "       [0.12534382, 0.60867238, 0.26598376],\n",
       "       [0.29798542, 0.39757332, 0.30444123],\n",
       "       [0.39456391, 0.36097099, 0.24446508],\n",
       "       [0.18415985, 0.58016014, 0.23568006],\n",
       "       [0.11282491, 0.17233451, 0.71484056],\n",
       "       [0.16565745, 0.13436942, 0.69997311],\n",
       "       [0.29499307, 0.32397327, 0.38103366],\n",
       "       [0.35760807, 0.35596277, 0.28642918],\n",
       "       [0.60446391, 0.14779335, 0.24774277],\n",
       "       [0.58481497, 0.13863707, 0.27654794],\n",
       "       [0.65916687, 0.13954222, 0.20129086],\n",
       "       [0.26940963, 0.44509611, 0.28549431],\n",
       "       [0.21965925, 0.35077374, 0.42956699],\n",
       "       [0.49596402, 0.27171826, 0.23231769],\n",
       "       [0.48474397, 0.23800208, 0.27725397],\n",
       "       [0.66801411, 0.05700217, 0.2749837 ],\n",
       "       [0.52506237, 0.19259802, 0.28233962],\n",
       "       [0.09932498, 0.09483508, 0.80583996],\n",
       "       [0.26695628, 0.51694109, 0.21610265],\n",
       "       [0.16419627, 0.51913923, 0.31666453],\n",
       "       [0.49600908, 0.19174446, 0.31224652],\n",
       "       [0.42914514, 0.21165528, 0.35919958],\n",
       "       [0.08317579, 0.80820405, 0.10862017],\n",
       "       [0.31361033, 0.33594991, 0.35043976],\n",
       "       [0.20798493, 0.16454611, 0.62746894],\n",
       "       [0.16601837, 0.66715798, 0.16682364],\n",
       "       [0.51796472, 0.15805701, 0.32397825],\n",
       "       [0.03059832, 0.89907432, 0.07032736],\n",
       "       [0.55720791, 0.20858068, 0.23421137],\n",
       "       [0.35378812, 0.28576341, 0.36044848]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_combined\n",
    "#      ([[0.82734951, 0.07696167, 0.0956888 ],\n",
    "#        [0.09184527, 0.73428428, 0.17387044],\n",
    "#        [0.75341365, 0.09070889, 0.1558775 ],\n",
    "#        [0.28543372, 0.17469092, 0.53987533],\n",
    "#        [0.06915807, 0.06648109, 0.86436084],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc834b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:32:31.635742Z",
     "iopub.status.busy": "2024-07-25T14:32:31.635014Z",
     "iopub.status.idle": "2024-07-25T14:32:31.648212Z",
     "shell.execute_reply": "2024-07-25T14:32:31.647468Z"
    },
    "papermill": {
     "duration": 0.03179,
     "end_time": "2024-07-25T14:32:31.650346",
     "exception": false,
     "start_time": "2024-07-25T14:32:31.618556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[\"winner_model_a\"] = logits_combined[:,0]\n",
    "test[\"winner_model_b\"] = logits_combined[:,1]\n",
    "test[\"winner_tie\"] = logits_combined[:,2]\n",
    "test = test.fillna(1/3.)\n",
    "test[[\"id\", \"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "673f3281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T14:32:31.686636Z",
     "iopub.status.busy": "2024-07-25T14:32:31.686310Z",
     "iopub.status.idle": "2024-07-25T14:32:31.719446Z",
     "shell.execute_reply": "2024-07-25T14:32:31.718519Z"
    },
    "papermill": {
     "duration": 0.052408,
     "end_time": "2024-07-25T14:32:31.721895",
     "exception": false,
     "start_time": "2024-07-25T14:32:31.669487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>fold</th>\n",
       "      <th>full_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[Is it morally right to try to have a certain ...</td>\n",
       "      <td>[The question of whether it is morally right t...</td>\n",
       "      <td>[As an AI, I don't have personal beliefs or op...</td>\n",
       "      <td>0.826433</td>\n",
       "      <td>0.077030</td>\n",
       "      <td>0.096537</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nIs it morally right t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>370945</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>[\"Bacteria is life on Mars but a heartbeat isn...</td>\n",
       "      <td>[Dune]</td>\n",
       "      <td>[This quote seems to be referencing the debate...</td>\n",
       "      <td>0.088298</td>\n",
       "      <td>0.740664</td>\n",
       "      <td>0.171038</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\n\"Bacteria is life on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>738614</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>gpt4all-13b-snoozy</td>\n",
       "      <td>[What's the best first move in tic-tac-toe?, T...</td>\n",
       "      <td>[The best first move in tic-tac-toe is often c...</td>\n",
       "      <td>[The best first move in tic-tac-toe is to plac...</td>\n",
       "      <td>0.734569</td>\n",
       "      <td>0.095770</td>\n",
       "      <td>0.169661</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nWhat's the best first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>862324</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[Write me a poem in urdu in the style of Iqbal...</td>\n",
       "      <td>[Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan ...</td>\n",
       "      <td>[In the realm of selflessness dwells the true ...</td>\n",
       "      <td>0.278965</td>\n",
       "      <td>0.176294</td>\n",
       "      <td>0.544742</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nWrite me a poem in ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1827787</td>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[Given a passage and some supplementary inform...</td>\n",
       "      <td>[Refined passage: \\nThe person in the photo is...</td>\n",
       "      <td>[Refined passage: \\nThe person in the photo is...</td>\n",
       "      <td>0.066947</td>\n",
       "      <td>0.066602</td>\n",
       "      <td>0.866452</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nGiven a passage and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>37132737</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>pplx-70b-online</td>\n",
       "      <td>[What is the basque country?]</td>\n",
       "      <td>[The Basque Country is a region located in the...</td>\n",
       "      <td>[The Basque Country is a region located in the...</td>\n",
       "      <td>0.166018</td>\n",
       "      <td>0.667158</td>\n",
       "      <td>0.166824</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nWhat is the basque co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>37206390</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>[what is the song in the movie snatch that pla...</td>\n",
       "      <td>[The song that plays during the hare and dog s...</td>\n",
       "      <td>[The song that plays during the hare coursing ...</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.158057</td>\n",
       "      <td>0.323978</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nwhat is the song in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>37951752</td>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>[Would you like to play my DnD game?, Ok, make...</td>\n",
       "      <td>[As an AI language model, I'm not capable of p...</td>\n",
       "      <td>[Thank you for the invitation! I'd be happy to...</td>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.899074</td>\n",
       "      <td>0.070327</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nWould you like to pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>38558732</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[Could you please explain what does it mean fo...</td>\n",
       "      <td>[In physics, the concept of time being fundame...</td>\n",
       "      <td>[When time is considered fundamental, it means...</td>\n",
       "      <td>0.557208</td>\n",
       "      <td>0.208581</td>\n",
       "      <td>0.234211</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nCould you please expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>38760658</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[Write an interesting short sci Fi story]</td>\n",
       "      <td>[In the year 2075, humanity made a groundbreak...</td>\n",
       "      <td>[In the year 2150, the world was on the brink ...</td>\n",
       "      <td>0.353788</td>\n",
       "      <td>0.285763</td>\n",
       "      <td>0.360448</td>\n",
       "      <td>0</td>\n",
       "      <td>## Turn 1\\n\\n### Prompt\\nWrite an interesting ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                model_a                     model_b  \\\n",
       "0       30192     gpt-4-1106-preview                  gpt-4-0613   \n",
       "7      370945             gemini-pro                  claude-2.0   \n",
       "13     738614           mpt-30b-chat          gpt4all-13b-snoozy   \n",
       "14     862324             vicuna-13b                   koala-13b   \n",
       "29    1827787  deepseek-llm-67b-chat          gpt-4-1106-preview   \n",
       "..        ...                    ...                         ...   \n",
       "502  37132737     gpt-3.5-turbo-0613             pplx-70b-online   \n",
       "504  37206390             gpt-4-0613          gpt-4-0125-preview   \n",
       "516  37951752  deepseek-llm-67b-chat  mixtral-8x7b-instruct-v0.1   \n",
       "519  38558732       llama-2-13b-chat         mistral-7b-instruct   \n",
       "520  38760658         mistral-medium          gpt-3.5-turbo-1106   \n",
       "\n",
       "                                                prompt  \\\n",
       "0    [Is it morally right to try to have a certain ...   \n",
       "7    [\"Bacteria is life on Mars but a heartbeat isn...   \n",
       "13   [What's the best first move in tic-tac-toe?, T...   \n",
       "14   [Write me a poem in urdu in the style of Iqbal...   \n",
       "29   [Given a passage and some supplementary inform...   \n",
       "..                                                 ...   \n",
       "502                      [What is the basque country?]   \n",
       "504  [what is the song in the movie snatch that pla...   \n",
       "516  [Would you like to play my DnD game?, Ok, make...   \n",
       "519  [Could you please explain what does it mean fo...   \n",
       "520          [Write an interesting short sci Fi story]   \n",
       "\n",
       "                                            response_a  \\\n",
       "0    [The question of whether it is morally right t...   \n",
       "7                                               [Dune]   \n",
       "13   [The best first move in tic-tac-toe is often c...   \n",
       "14   [Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan ...   \n",
       "29   [Refined passage: \\nThe person in the photo is...   \n",
       "..                                                 ...   \n",
       "502  [The Basque Country is a region located in the...   \n",
       "504  [The song that plays during the hare and dog s...   \n",
       "516  [As an AI language model, I'm not capable of p...   \n",
       "519  [In physics, the concept of time being fundame...   \n",
       "520  [In the year 2075, humanity made a groundbreak...   \n",
       "\n",
       "                                            response_b  winner_model_a  \\\n",
       "0    [As an AI, I don't have personal beliefs or op...        0.826433   \n",
       "7    [This quote seems to be referencing the debate...        0.088298   \n",
       "13   [The best first move in tic-tac-toe is to plac...        0.734569   \n",
       "14   [In the realm of selflessness dwells the true ...        0.278965   \n",
       "29   [Refined passage: \\nThe person in the photo is...        0.066947   \n",
       "..                                                 ...             ...   \n",
       "502  [The Basque Country is a region located in the...        0.166018   \n",
       "504  [The song that plays during the hare coursing ...        0.517965   \n",
       "516  [Thank you for the invitation! I'd be happy to...        0.030598   \n",
       "519  [When time is considered fundamental, it means...        0.557208   \n",
       "520  [In the year 2150, the world was on the brink ...        0.353788   \n",
       "\n",
       "     winner_model_b  winner_tie  fold  \\\n",
       "0          0.077030    0.096537     0   \n",
       "7          0.740664    0.171038     0   \n",
       "13         0.095770    0.169661     0   \n",
       "14         0.176294    0.544742     0   \n",
       "29         0.066602    0.866452     0   \n",
       "..              ...         ...   ...   \n",
       "502        0.667158    0.166824     0   \n",
       "504        0.158057    0.323978     0   \n",
       "516        0.899074    0.070327     0   \n",
       "519        0.208581    0.234211     0   \n",
       "520        0.285763    0.360448     0   \n",
       "\n",
       "                                           full_prompt  \n",
       "0    ## Turn 1\\n\\n### Prompt\\nIs it morally right t...  \n",
       "7    ## Turn 1\\n\\n### Prompt\\n\"Bacteria is life on ...  \n",
       "13   ## Turn 1\\n\\n### Prompt\\nWhat's the best first...  \n",
       "14   ## Turn 1\\n\\n### Prompt\\nWrite me a poem in ur...  \n",
       "29   ## Turn 1\\n\\n### Prompt\\nGiven a passage and s...  \n",
       "..                                                 ...  \n",
       "502  ## Turn 1\\n\\n### Prompt\\nWhat is the basque co...  \n",
       "504  ## Turn 1\\n\\n### Prompt\\nwhat is the song in t...  \n",
       "516  ## Turn 1\\n\\n### Prompt\\nWould you like to pla...  \n",
       "519  ## Turn 1\\n\\n### Prompt\\nCould you please expl...  \n",
       "520  ## Turn 1\\n\\n### Prompt\\nWrite an interesting ...  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741de9a8",
   "metadata": {
    "papermill": {
     "duration": 0.016026,
     "end_time": "2024-07-25T14:32:31.755634",
     "exception": false,
     "start_time": "2024-07-25T14:32:31.739608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5435792,
     "sourceId": 9020401,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5435777,
     "sourceId": 9033354,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 189687666,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 344.503969,
   "end_time": "2024-07-25T14:32:32.793388",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-25T14:26:48.289419",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
